{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e035a199",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "\n",
    "In this assignment we will apply the linearized inversion with FWI and compare the results with FWI alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832d676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import deepwave\n",
    "from scipy import signal,interpolate\n",
    "from torchvision.transforms import GaussianBlur \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "def Plot_model(m,par,name=None,**kwargs):\n",
    "    \"\"\"\n",
    "    plot a 2D model \n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    m: 2D numpy array\n",
    "         array containing the model\n",
    "    par : dictionary \n",
    "        dictionary containing the axis points,increments, and origin points. \n",
    "        (i.e,par['ox'],par['dx'],par['nx'],par['nz'],par['dz'],par['oz'])\n",
    "    ----------\n",
    "    Optional \n",
    "    ----------\n",
    "    vmax: float\n",
    "          Maximum value for the plot \n",
    "    vmin: float\n",
    "          Minimum value for plot\n",
    "    cmap: str\n",
    "          Matplotlib-colormap\n",
    "    name: str \n",
    "          to save the figure with the corresponding 'name' in a 'Fig' directory\n",
    "    \"\"\"\n",
    "\n",
    "    vmax = kwargs.pop('vmax', None)\n",
    "    vmin = kwargs.pop('vmin', None)\n",
    "    name = kwargs.pop('name', None)\n",
    "    cmap = kwargs.pop('cmap', 'jet')\n",
    "    title = kwargs.pop('title', None)\n",
    "    if 'vmin'==None: vmin, _ = np.percentile(m.T,[2,98])\n",
    "    if 'vmax'==None: _, vmax = np.percentile(m.T,[2,98])\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.imshow(m,cmap=cmap,vmin=vmin,vmax=vmax,extent=[par['ox'],par['dx']*par['nx'],par['nz']*par['dz'],par['oz']])\n",
    "    plt.axis('tight')\n",
    "    plt.xlabel('Distance (km)',fontsize=18,weight='heavy')\n",
    "    plt.ylabel('Depth (km)',fontsize=18,weight='heavy')\n",
    "    plt.colorbar(label='km/s')\n",
    "    if title != None: plt.title(title)\n",
    "    if name!=None:\n",
    "        if not os.path.isdir('./Fig'): os.mkdir('./Fig')\n",
    "        plt.savefig('./Fig/'+name,bbox_inches='tight')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9209e6",
   "metadata": {},
   "source": [
    "## Setting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819e0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "# Define the model and achuisition parameters\n",
    "par = {'nx':601,   'dx':0.015, 'ox':0,\n",
    "       'nz':221,   'dz':0.015, 'oz':0,\n",
    "       'ns':30,    'ds':0.3,   'osou':0,  'sz':0.03,\n",
    "       'nr':300,   'dr':0.03,  'orec':0,  'rz':0.03,\n",
    "       'nt':3000,  'dt':0.0013,  'ot':0,\n",
    "       'freq':15,\n",
    "       'num_batches':10, # increase thus number if you have a CUDA out of memory error \n",
    "       'FWI_itr': 100,\n",
    "       'LSRTM_itr': ,  # inner iteration\n",
    "       'num_dims': 2 \n",
    "      }\n",
    "\n",
    "# Mapping the par dictionary to variables \n",
    "for k in par:\n",
    "    locals()[k] = par[k]\n",
    "    \n",
    "fs = 1/dt # sampling frequency\n",
    "\n",
    "\n",
    "# Don't change the below two lines \n",
    "num_sources_per_shot=1\n",
    "num_dims = 2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f04f31f",
   "metadata": {},
   "source": [
    "## Loading input files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the true model for forward modelling \n",
    "path = '../Assignment1/'\n",
    "velocity_file= path + 'Marm.bin' # true model \n",
    "\n",
    "#  Load the velocity model \n",
    "m_true =(np.fromfile(velocity_file, np.float32)\n",
    "              .reshape(nz, nx))\n",
    "\n",
    "\n",
    "m0 = gaussian_filter(m_true,sigma=(15,5)) # You can change this if you like but don't use a very small smoothing\n",
    "\n",
    "\n",
    "\n",
    "# Get a mask for the water layer (P.S water veocity = 1.5 km/s)\n",
    "msk = np.ones_like(m_true)\n",
    "msk[:20,] =  0\n",
    "\n",
    "\n",
    "\n",
    "# convert to tensor\n",
    "m_true = torch.tensor(m_true,dtype=torch.float32)\n",
    "m0 = torch.tensor(m0,dtype=torch.float32)\n",
    "msk = torch.tensor(msk,dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "Plot_model(m_true,par)\n",
    "Plot_model(m0,par)\n",
    "\n",
    "print(f'vel shape {m_true.shape} (nx,nz)  || init shape {m0.shape} (nx,nz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3517e1ae",
   "metadata": {},
   "source": [
    "## This time we also need a scattering (perturbation) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = torch.zeros_like(m0)  # Scattering model ( perturbation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3001b7",
   "metadata": {},
   "source": [
    "## The acquisition set-up\n",
    "\n",
    " Create arrays containing the source and receiver locations\n",
    " \n",
    "    x_s: Source locations [num_shots, num_sources_per_shot, num_dimensions].\n",
    "    \n",
    "    x_r: Receiver locations [num_shots, num_receivers_per_shot, num_dimensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70111bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_s = torch.zeros(ns, num_sources_per_shot, num_dims)\n",
    "x_s[:, 0, 1] = torch.arange(ns).float() * ds  \n",
    "x_s[:, 0, 0] = sz\n",
    "\n",
    "x_r = torch.zeros(ns, nr, num_dims)\n",
    "x_r[0, :, 1] = torch.arange(nr).float() * dr\n",
    "x_r[:, :, 1] = x_r[0, :, 1].repeat(ns, 1)\n",
    "x_r[:, :, 0] = rz\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbf1c0",
   "metadata": {},
   "source": [
    "## Create source wavelet\n",
    "    [nt, num_shots, num_sources_per_shot]\n",
    "\n",
    "I use Deepwave's Ricker wavelet function. The result is a normal Tensor - you can use any function to create the wavelet but it needs to be converted to tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5557bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "source_wavelet = (deepwave.wavelets.ricker(freq, nt, dt, 1/freq)\n",
    "                          .reshape(-1, 1, 1)\n",
    "                          .repeat(1, ns, num_sources_per_shot))\n",
    "print(source_wavelet.shape)\n",
    "\n",
    "\n",
    "plt.plot(np.arange(0,nt)*dt,source_wavelet[:,0,0])\n",
    "plt.xlabel('Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7be863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91533d11",
   "metadata": {},
   "source": [
    "## Forward modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highpass_filter(freq, wavelet, dt):\n",
    "    \"\"\"\n",
    "    Filter out low frequency\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    freq : :obj:`int`\n",
    "    Cut-off frequency\n",
    "    wavelet : :obj:`torch.Tensor`\n",
    "    Tensor of wavelet\n",
    "    dt : :obj:`float32`\n",
    "    Time sampling\n",
    "    Returns\n",
    "    -------\n",
    "    : :obj:`torch.Tensor`\n",
    "    Tensor of highpass frequency wavelet\n",
    "    \"\"\"\n",
    "\n",
    "    sos = signal.butter(6,  freq / (0.5 * (1 / dt)), 'hp', output='sos') \n",
    "    return torch.tensor( signal.sosfiltfilt(sos, wavelet,axis=0).copy(),dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Create 'true' data\n",
    "prop = deepwave.scalar.Propagator({'vp': m_true.to(device)}, dx) # create a propegator \n",
    "\n",
    "data_true = prop(source_wavelet.to(device),\n",
    "                                x_s.to(device),\n",
    "                                x_r.to(device), dt).cpu()\n",
    "\n",
    "\n",
    "# Remove low frequency\n",
    "source_wavelet = highpass_filter(4,source_wavelet,dt)\n",
    "data_true = highpass_filter(4,data_true,dt)                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfefc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot one shot gather\n",
    "d_vmin, d_vmax = np.percentile(data_true[:,0].cpu().numpy(), [2,98])\n",
    "\n",
    "plt.imshow(data_true[:,0,].cpu().numpy(), aspect='auto',\n",
    "           vmin=-d_vmax, vmax=d_vmax,cmap='bwr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e326be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone just to save the initial model. \n",
    "m0 = m0.to(device)\n",
    "m0.requires_grad = True\n",
    "\n",
    "dm = dm.to(device)\n",
    "dm.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1917aef1",
   "metadata": {},
   "source": [
    "##  Set the optimizer and the criterion \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de34371",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer_m0 = torch.optim.Adam([{'params': [m0], 'lr': 0.01}])   # To update the background\n",
    "optimizer_dm = torch.optim.Adam([{'params': [dm], 'lr': 0.01}])   # To update the perturbation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee89d1",
   "metadata": {},
   "source": [
    "## Main inversion loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a00ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Iterative inversion loop\n",
    "num_shots_per_batch = int(ns / num_batches)\n",
    "epoch_loss = [] \n",
    "updates = []\n",
    "gradients = []\n",
    "msk = msk.to(device)\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "for epoch in range(FWI_itr):\n",
    "  running_loss=0\n",
    "  optimizer_m0.zero_grad()  # zero out the gradient   \n",
    "\n",
    "\n",
    "  for inner_epoch in range (LSRTM_itr):        \n",
    "        # ------------- To do \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "  # FWI       \n",
    "  # ------- To do ( add the scattering to the background  )\n",
    "    \n",
    "  # FWI iteration as before  \n",
    "  for it in range(num_batches):\n",
    "    prop = deepwave.scalar.Propagator({'vp': m0}, dx)\n",
    "    batch_src_wvl = source_wavelet[:,it::num_batches,].to(device)\n",
    "    batch_data_true = data_true[:,it::num_batches].to(device)\n",
    "    batch_x_s = x_s[it::num_batches].to(device)\n",
    "    batch_x_r = x_r[it::num_batches].to(device)\n",
    "    data_pred = prop(batch_src_wvl, batch_x_s, batch_x_r, dt)\n",
    "    loss = criterion(data_pred, batch_data_true)\n",
    "    running_loss += loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "  epoch_loss.append(running_loss)     \n",
    "\n",
    "  # Apply some operations to the gradient\n",
    "  if epoch==0: gmax = (torch.abs(m0.grad)*msk).max()\n",
    "  m0.grad = m0.grad /gmax *msk   # normalizing by the first gradient and mask the wter layer\n",
    "    \n",
    "  # update the m0 \n",
    "  optimizer_m0.step()\n",
    "  print('Epoch:', epoch, 'Loss: ', running_loss)\n",
    "\n",
    "    \n",
    "  # save the vel updates and gradients for each iteration\n",
    "  updates.append(m0.detach().clone().cpu().numpy())\n",
    "  gradients.append(m0.grad.cpu().detach().numpy())  \n",
    "    \n",
    "  # plotting every 10 itr   \n",
    "  if epoch % 10 == 0:\n",
    "    Plot_model(m0.cpu().detach().numpy(),par) \n",
    "    Plot_model(m0.grad.cpu().detach().numpy(),par,cmap='seismic') \n",
    "    plt.show()\n",
    "    \n",
    "t_end = time.time()\n",
    "print('Runtime:', (t_end - t_start)/60 ,'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4888663",
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = np.array(updates)\n",
    "gradients = np.array(gradients)\n",
    "obj = np.array(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9b9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470adf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bb15c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5965d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb0fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06798a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dcea05d95f5a5a2c52102d54be3d69ca1e4d72d81e0dd76681491d4ec5f910d5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
